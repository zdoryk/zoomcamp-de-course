{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df = pd.read_csv('yellow_tripdata_2021-01.csv', nrows=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<sqlalchemy.engine.base.Connection at 0x7fd23cff2800>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"Yellow taxi data\" (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='Yellow taxi data', con=engine))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# df_iter = pd.read_csv('yellow_tripdata_2021-01.csv', iterator=True, chunksize=100000)\n",
    "df_iter = pd.read_csv('green_tripdata_2019-01.csv', iterator=True, chunksize=100000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n0             2  2018-12-21 15:17:29   2018-12-21 15:18:57                  N   \n1             2  2019-01-01 00:10:16   2019-01-01 00:16:32                  N   \n2             2  2019-01-01 00:27:11   2019-01-01 00:31:38                  N   \n3             2  2019-01-01 00:46:20   2019-01-01 01:04:54                  N   \n4             2  2019-01-01 00:19:06   2019-01-01 00:39:43                  N   \n...         ...                  ...                   ...                ...   \n99995         2  2019-01-06 09:56:09   2019-01-06 10:01:30                  N   \n99996         2  2019-01-06 09:12:49   2019-01-06 09:52:38                  N   \n99997         2  2019-01-06 09:02:06   2019-01-06 09:37:42                  N   \n99998         2  2019-01-06 09:55:01   2019-01-06 10:04:34                  N   \n99999         2  2019-01-06 09:59:04   2019-01-06 10:24:33                  N   \n\n       RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n0               1           264           264                5           0.00   \n1               1            97            49                2           0.86   \n2               1            49           189                2           0.66   \n3               1           189            17                2           2.68   \n4               1            82           258                1           4.53   \n...           ...           ...           ...              ...            ...   \n99995           1           130           216                1           1.23   \n99996           5           218            16                1          21.44   \n99997           5           139           188                1          14.77   \n99998           1            72           188                1           1.80   \n99999           5            89           225                1           7.03   \n\n       fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n0             3.00    0.5      0.5        0.00          0.00        NaN   \n1             6.00    0.5      0.5        0.00          0.00        NaN   \n2             4.50    0.5      0.5        0.00          0.00        NaN   \n3            13.50    0.5      0.5        2.96          0.00        NaN   \n4            18.00    0.5      0.5        0.00          0.00        NaN   \n...            ...    ...      ...         ...           ...        ...   \n99995         6.00    0.0      0.5        0.00          0.00        NaN   \n99996        47.65    0.0      0.5        0.00          5.76        NaN   \n99997        37.84    0.0      0.5        0.00          0.00        NaN   \n99998         8.50    0.0      0.5        0.00          0.00        NaN   \n99999        23.14    0.0      0.5        0.00          0.00        NaN   \n\n       improvement_surcharge  total_amount  payment_type  trip_type  \\\n0                        0.3          4.30             2          1   \n1                        0.3          7.30             2          1   \n2                        0.3          5.80             1          1   \n3                        0.3         19.71             1          1   \n4                        0.3         19.30             2          1   \n...                      ...           ...           ...        ...   \n99995                    0.3          6.80             2          1   \n99996                    0.0         53.91             1          2   \n99997                    0.0         38.34             1          2   \n99998                    0.3          9.30             1          1   \n99999                    0.0         23.64             1          2   \n\n       congestion_surcharge  \n0                       NaN  \n1                       NaN  \n2                       NaN  \n3                       NaN  \n4                       NaN  \n...                     ...  \n99995                   NaN  \n99996                   NaN  \n99997                   NaN  \n99998                   NaN  \n99999                   NaN  \n\n[100000 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VendorID</th>\n      <th>lpep_pickup_datetime</th>\n      <th>lpep_dropoff_datetime</th>\n      <th>store_and_fwd_flag</th>\n      <th>RatecodeID</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>ehail_fee</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>payment_type</th>\n      <th>trip_type</th>\n      <th>congestion_surcharge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2018-12-21 15:17:29</td>\n      <td>2018-12-21 15:18:57</td>\n      <td>N</td>\n      <td>1</td>\n      <td>264</td>\n      <td>264</td>\n      <td>5</td>\n      <td>0.00</td>\n      <td>3.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>4.30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2019-01-01 00:10:16</td>\n      <td>2019-01-01 00:16:32</td>\n      <td>N</td>\n      <td>1</td>\n      <td>97</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0.86</td>\n      <td>6.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>7.30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2019-01-01 00:27:11</td>\n      <td>2019-01-01 00:31:38</td>\n      <td>N</td>\n      <td>1</td>\n      <td>49</td>\n      <td>189</td>\n      <td>2</td>\n      <td>0.66</td>\n      <td>4.50</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>5.80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2019-01-01 00:46:20</td>\n      <td>2019-01-01 01:04:54</td>\n      <td>N</td>\n      <td>1</td>\n      <td>189</td>\n      <td>17</td>\n      <td>2</td>\n      <td>2.68</td>\n      <td>13.50</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>2.96</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>19.71</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2019-01-01 00:19:06</td>\n      <td>2019-01-01 00:39:43</td>\n      <td>N</td>\n      <td>1</td>\n      <td>82</td>\n      <td>258</td>\n      <td>1</td>\n      <td>4.53</td>\n      <td>18.00</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>19.30</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99995</th>\n      <td>2</td>\n      <td>2019-01-06 09:56:09</td>\n      <td>2019-01-06 10:01:30</td>\n      <td>N</td>\n      <td>1</td>\n      <td>130</td>\n      <td>216</td>\n      <td>1</td>\n      <td>1.23</td>\n      <td>6.00</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>6.80</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99996</th>\n      <td>2</td>\n      <td>2019-01-06 09:12:49</td>\n      <td>2019-01-06 09:52:38</td>\n      <td>N</td>\n      <td>5</td>\n      <td>218</td>\n      <td>16</td>\n      <td>1</td>\n      <td>21.44</td>\n      <td>47.65</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>5.76</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>53.91</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>2</td>\n      <td>2019-01-06 09:02:06</td>\n      <td>2019-01-06 09:37:42</td>\n      <td>N</td>\n      <td>5</td>\n      <td>139</td>\n      <td>188</td>\n      <td>1</td>\n      <td>14.77</td>\n      <td>37.84</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>38.34</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99998</th>\n      <td>2</td>\n      <td>2019-01-06 09:55:01</td>\n      <td>2019-01-06 10:04:34</td>\n      <td>N</td>\n      <td>1</td>\n      <td>72</td>\n      <td>188</td>\n      <td>1</td>\n      <td>1.80</td>\n      <td>8.50</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.3</td>\n      <td>9.30</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99999</th>\n      <td>2</td>\n      <td>2019-01-06 09:59:04</td>\n      <td>2019-01-06 10:24:33</td>\n      <td>N</td>\n      <td>5</td>\n      <td>89</td>\n      <td>225</td>\n      <td>1</td>\n      <td>7.03</td>\n      <td>23.14</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>23.64</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = next(df_iter)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name='gree_taxi_data_2019_01',con=engine, if_exists='replace')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.73 s, sys: 60.2 ms, total: 3.79 s\n",
      "Wall time: 6.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "1000"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.to_sql(name='gree_taxi_data_2019_01',con=engine, if_exists='append')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m----> 2\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     df\u001B[38;5;241m.\u001B[39mlpep_pickup_datetime \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df\u001B[38;5;241m.\u001B[39mlpep_pickup_datetime)\n\u001B[1;32m      4\u001B[0m     df\u001B[38;5;241m.\u001B[39mlpep_dropoff_datetime \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df\u001B[38;5;241m.\u001B[39mlpep_dropoff_datetime)\n",
      "File \u001B[0;32m~/Projects/happiness/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1698\u001B[0m, in \u001B[0;36mTextFileReader.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1696\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m   1697\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1698\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1699\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m   1700\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Projects/happiness/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1810\u001B[0m, in \u001B[0;36mTextFileReader.get_chunk\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m   1808\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m   1809\u001B[0m     size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnrows \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow)\n\u001B[0;32m-> 1810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/happiness/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1771\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1772\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1773\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1774\u001B[0m     (\n\u001B[1;32m   1775\u001B[0m         index,\n\u001B[1;32m   1776\u001B[0m         columns,\n\u001B[1;32m   1777\u001B[0m         col_dict,\n\u001B[0;32m-> 1778\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Projects/happiness/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 230\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    232\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32m~/Projects/happiness/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:833\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mStopIteration\u001B[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    df = next(df_iter)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.to_sql(name='gree_taxi_data_2019_01',con=engine, if_exists='append')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get lookup file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-18 10:46:57--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\r\n",
      "Resolving github.com (github.com)... 140.82.121.3\r\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230118T094658Z&X-Amz-Expires=300&X-Amz-Signature=cafb301813cc9ae51f14aab39ed7ab74ac4b8602ad1c55b1e659cc4dc53648f7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2023-01-18 10:46:58--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230118T094658Z&X-Amz-Expires=300&X-Amz-Signature=cafb301813cc9ae51f14aab39ed7ab74ac4b8602ad1c55b1e659cc4dc53648f7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 12322 (12K) [application/octet-stream]\r\n",
      "Saving to: ‘taxi_zone_lookup.csv’\r\n",
      "\r\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2023-01-18 10:46:59 (56.7 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "     LocationID        Borough                     Zone service_zone\n0             1            EWR           Newark Airport          EWR\n1             2         Queens              Jamaica Bay    Boro Zone\n2             3          Bronx  Allerton/Pelham Gardens    Boro Zone\n3             4      Manhattan            Alphabet City  Yellow Zone\n4             5  Staten Island            Arden Heights    Boro Zone\n..          ...            ...                      ...          ...\n260         261      Manhattan       World Trade Center  Yellow Zone\n261         262      Manhattan           Yorkville East  Yellow Zone\n262         263      Manhattan           Yorkville West  Yellow Zone\n263         264        Unknown                       NV          NaN\n264         265        Unknown                      NaN          NaN\n\n[265 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LocationID</th>\n      <th>Borough</th>\n      <th>Zone</th>\n      <th>service_zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>EWR</td>\n      <td>Newark Airport</td>\n      <td>EWR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Queens</td>\n      <td>Jamaica Bay</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Bronx</td>\n      <td>Allerton/Pelham Gardens</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Manhattan</td>\n      <td>Alphabet City</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Staten Island</td>\n      <td>Arden Heights</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>261</td>\n      <td>Manhattan</td>\n      <td>World Trade Center</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>262</td>\n      <td>Manhattan</td>\n      <td>Yorkville East</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>263</td>\n      <td>Manhattan</td>\n      <td>Yorkville West</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>264</td>\n      <td>Unknown</td>\n      <td>NV</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>265</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>265 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones = pd.read_csv('taxi_zone_lookup.csv')\n",
    "df_zones"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "265"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
